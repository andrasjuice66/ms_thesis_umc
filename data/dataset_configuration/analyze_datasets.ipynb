{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d71cd9a4",
      "metadata": {},
      "source": [
        "# Dataset Analysis with Configurable Train / Val / Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "054c1c12",
      "metadata": {
        "name": "config"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# CONFIG – edit only the variables below\n",
        "# ------------------------------------------------------------\n",
        "TRAIN_DATASETS      = ['camcan', 'dallas_lifespan', 'npc', 'nimh_rv', 'oasis3']  # example\n",
        "TEST_DATASETS       = ['ixi', 'boldvar']                    # example\n",
        "\n",
        "VAL_FRACTION        = 0.10   # 0.10 → 10 % of TRAIN becomes VAL\n",
        "RANDOM_STATE        = 42     # reproducible shuffles\n",
        "DROP_OTHER_DATASETS = True   # ignore rows from datasets not listed\n",
        "\n",
        "# --- global analysis parameters -------------------------------------------\n",
        "AGE_MIN, AGE_MAX = 18, 85\n",
        "MODALITIES       = ['t1', 't2', 'flair']\n",
        "\n",
        "# --- minimal subset parameters (hyper-parameter tuning) -------------------\n",
        "SUBSET_SEX            = 'male'   # 'male' or 'female'\n",
        "SUBSET_MODALITY       = 't1'     # any value from MODALITIES\n",
        "SUBSET_AGE_MIN, SUBSET_AGE_MAX = 30, 40  # inclusive range\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "572343f2",
      "metadata": {
        "name": "imports"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "import itertools, warnings, uuid, sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set(style='whitegrid', context='notebook')\n",
        "\n",
        "# define labels directory as a sibling to this script's dir\n",
        "LABEL_DIR = Path('..') / 'labels'\n",
        "LABEL_DIR.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "64bff1d6",
      "metadata": {
        "name": "helpers"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Helper functions\n",
        "# ------------------------------------------------------------\n",
        "def clean_df(raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Standardise column names & values, drop unusable rows.\"\"\"\n",
        "    df = raw.copy()\n",
        "    df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "    df['age'] = pd.to_numeric(df['age'], errors='coerce').round(2).astype(float)\n",
        "    df['sex'] = (df['sex'].astype(str).str.lower().str.strip()\n",
        "                   .map({'m':'male','male':'male','1':'male',\n",
        "                        'f':'female','female':'female','2':'female'}))\n",
        "    df['modality'] = (df['modality'].astype(str).str.lower()\n",
        "                        .str.extract('(t1|t2|flair)', expand=False))\n",
        "\n",
        "    df = (df.dropna(subset=['age','sex','modality'])\n",
        "            .query('@AGE_MIN <= age <= @AGE_MAX'))\n",
        "    return df\n",
        "\n",
        "def coverage_report(df: pd.DataFrame, title: str = ''):\n",
        "    \"\"\"Report coverage of all (age_bin, sex, modality) combos.\"\"\"\n",
        "    df2 = df.copy()\n",
        "    # integer age bins\n",
        "    df2['age_bin'] = df2['age'].astype(int)\n",
        "    # expected combinations\n",
        "    all_combos = set(itertools.product(range(AGE_MIN, AGE_MAX+1), ['male','female'], MODALITIES))\n",
        "    # observed combinations\n",
        "    present = set(zip(df2['age_bin'], df2['sex'], df2['modality']))\n",
        "    missing = sorted(all_combos - present)\n",
        "    print(f'=== {title or \"Dataset\"} ===')\n",
        "    print(f'Expected combinations : {len(all_combos)}')\n",
        "    print(f'Observed combinations : {len(present)}')\n",
        "    print(f'Missing combinations  : {len(missing)}\\n')\n",
        "    if missing:\n",
        "        display(pd.DataFrame(missing, columns=['age','sex','modality']))\n",
        "    # one sample per combo\n",
        "    subset = (df2.groupby(['age_bin','sex','modality'], group_keys=False)\n",
        "                   .sample(n=1, random_state=42)\n",
        "                   .reset_index(drop=True))\n",
        "    subset = subset.drop(columns=['age_bin'])\n",
        "    return subset\n",
        "\n",
        "def quick_plots(df: pd.DataFrame, title: str = ''):\n",
        "    print(f'\\n### {title} – shape: {df.shape}\\n')\n",
        "    display(df.head())\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18,4))\n",
        "    sns.countplot(x='modality', data=df, ax=axes[0]); axes[0].set_title('Modality')\n",
        "    sns.countplot(x='sex',      data=df, ax=axes[1]); axes[1].set_title('Sex')\n",
        "    sns.histplot(df['age'], bins=20, kde=True, ax=axes[2]); axes[2].set_title('Age')\n",
        "    plt.suptitle(title); plt.tight_layout(); plt.show()\n",
        "    for col in ['modality', 'sex']:\n",
        "        g = sns.catplot(data=df, x=col, col='dataset', kind='count', col_wrap=4, sharey=False)\n",
        "        g.fig.suptitle(f'{col.capitalize()} distribution per dataset', y=1.02)\n",
        "        plt.show()\n",
        "    g = sns.displot(data=df, x='age', col='dataset', bins=20, col_wrap=4, kde=True)\n",
        "    g.fig.suptitle('Age distribution per dataset', y=1.02)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8647c372",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------------- Missing-data & count heat-map helpers -----------------\n",
        "import numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
        "\n",
        "def plot_missing_matrix(df: pd.DataFrame,\n",
        "                        title: str = '',\n",
        "                        *, group_by=1,\n",
        "                        save_as: str | None = None,\n",
        "                        cmap: str = 'binary'):\n",
        "    \"\"\"\n",
        "    Visualise coverage as a white/black matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    ages   = list(range(AGE_MIN, AGE_MAX + 1, group_by))\n",
        "    combos = [(m, s) for m in MODALITIES for s in ['male', 'female']]\n",
        "    mat    = np.ones((len(combos), len(ages)), dtype=int)\n",
        "\n",
        "    present = set(zip(df['age'], df['sex'], df['modality']))\n",
        "\n",
        "    for r, (mod, sex) in enumerate(combos):\n",
        "        for c, age in enumerate(ages):\n",
        "            if all((a, sex, mod) not in present\n",
        "                   for a in range(age, min(age + group_by, AGE_MAX + 1))):\n",
        "                mat[r, c] = 0\n",
        "\n",
        "    fig_h = max(3, 0.6 * len(combos))\n",
        "    plt.figure(figsize=(18, fig_h))\n",
        "    sns.heatmap(mat,\n",
        "                cmap=cmap,\n",
        "                cbar=False,\n",
        "                xticklabels=ages,\n",
        "                yticklabels=[f'{m.upper()} – {sex.capitalize()}' for m, sex in combos])\n",
        "\n",
        "    plt.title(f'{title}\\nblack = present, white = missing', fontsize=14)\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Modality / Sex')\n",
        "    plt.xticks(rotation=90, fontsize=8)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_as:\n",
        "        plt.savefig(save_as, dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "def plot_count_heatmap(df: pd.DataFrame,\n",
        "                       title: str = '',\n",
        "                       *,\n",
        "                       group_by: int = 1,        # age bin width (years)\n",
        "                       cmap: str   = 'YlGnBu',\n",
        "                       log_scale: bool = False,\n",
        "                       save_as: str | None = None):\n",
        "    \n",
        "\n",
        "    needed = {'age', 'sex', 'modality'}\n",
        "    if not needed.issubset(df.columns):\n",
        "        raise ValueError(f'DataFrame must contain {needed}')\n",
        "\n",
        "    present = df.copy()\n",
        "    present['age_bin'] = (present['age'] // group_by) * group_by\n",
        "    ages   = list(range(AGE_MIN, AGE_MAX + 1, group_by))\n",
        "    combos = [(m, s) for m in MODALITIES for s in ['male', 'female']]\n",
        "\n",
        "    mat = np.zeros((len(combos), len(ages)), dtype=int)\n",
        "    for r, (mod, sex) in enumerate(combos):\n",
        "        sub = present[(present['modality'] == mod) & (present['sex'] == sex)]\n",
        "        counts = sub.groupby('age_bin').size()\n",
        "        for c, age in enumerate(ages):\n",
        "            mat[r, c] = counts.get(age, 0)\n",
        "\n",
        "    plot_mat = np.log1p(mat) if log_scale else mat\n",
        "    cbar_lbl = 'logₑ(1 + count)' if log_scale else 'count'\n",
        "\n",
        "    fig_h = max(3, 0.6 * len(combos))\n",
        "    plt.figure(figsize=(18, fig_h))\n",
        "    sns.heatmap(plot_mat,\n",
        "                cmap=cmap,\n",
        "                annot=True,\n",
        "                fmt='.0f',\n",
        "                linewidths=.5,\n",
        "                cbar_kws={'label': cbar_lbl},\n",
        "                xticklabels=ages,\n",
        "                yticklabels=[f'{m.upper()} – {s.capitalize()}' for m, s in combos])\n",
        "\n",
        "    plt.title(f'{title}\\\\ncell value = number of images', fontsize=14)\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Modality / Sex')\n",
        "    plt.xticks(rotation=90, fontsize=8)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_as:\n",
        "        plt.savefig(save_as, dpi=150)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4542e6cb",
      "metadata": {
        "name": "load_data"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Load Excel and concatenate all sheets\n",
        "# ------------------------------------------------------------\n",
        "EXCEL_FILE = 'all_datasets_converted.xlsx'  # change path if needed\n",
        "\n",
        "sheets = pd.read_excel(EXCEL_FILE, sheet_name=None)\n",
        "df_list = []\n",
        "for name, sheet in sheets.items():\n",
        "    if 'dataset' not in sheet.columns or sheet['dataset'].isna().all():\n",
        "        sheet['dataset'] = name\n",
        "    df_list.append(sheet)\n",
        "\n",
        "df_all = pd.concat(df_list, ignore_index=True)\n",
        "df_all = clean_df(df_all)\n",
        "print('Loaded & cleaned data →', df_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4fbd4a5c",
      "metadata": {},
      "outputs": [],
      "source": [
        "nimhrv_filenames = [r\"*HighResHippo*\"]  # Regex for substring match\n",
        "\n",
        "oasis_filenames = [\n",
        "    r\"*sub-OAS31103_ses-d0170_run-01_T1w*\",\n",
        "    r\"*sub-OAS30516_ses-d0225_run-01_T1w*\",\n",
        "    r\"*sub-OAS30062_ses-d0087_run-01_T1w*\",\n",
        "    r\"*sub-OAS30558_ses-d0061_run-01_T1w*\",\n",
        "    r\"*sub-OAS30472_ses-d0058_run-01_T1w*\",\n",
        "    r\"*sub-OAS30106_ses-d2982_run-01_T1w*\",\n",
        "    r\"*sub-OAS30803_ses-d0086_run-01_T1w*\",\n",
        "    r\"*sub-OAS30367_ses-d0055_run-01_T1w*\",\n",
        "    r\"*sub-OAS30660_ses-d0087_run-01_T1w*\",\n",
        "    r\"*sub-OAS30032_ses-d0262_run-01_T1w*\",\n",
        "    r\"*sub-OAS30444_ses-d0001_run-04_T1w*\",\n",
        "    r\"*sub-OAS30059_ses-d0230_run-01_T1w*\",\n",
        "    r\"*sub-OAS30455_ses-d0171_run-01_T1w*\",\n",
        "    r\"*sub-OAS30969_ses-d3306_run-01_T1w*\",\n",
        "    r\"*sub-OAS30103_ses-d3306_run-01_T1w*\",\n",
        "    r\"*sub-OAS31072_ses-d0833_run-01_T1w*\",\n",
        "    r\"*sub-OAS30059_ses-d0230_run-04_T1w*\",\n",
        "    r\"*sub-OAS30444_ses-d0001_run-01_T1w*\",\n",
        "    r\"*sub-OAS30297_ses-d0105_run-01_T1w*\",\n",
        "    r\"*sub-OAS30689_ses-d0282_run-01_T1w*\",\n",
        "    r\"*sub-OAS30181_ses-d0129_run-01_T1w*\",\n",
        "    r\"*sub-OAS30785_ses-d0768_run-01_T1w*\",\n",
        "    r\"*sub-OAS30365_ses-d5600_run-01_T1w*\",\n",
        "    r\"*sub-OAS30558_ses-d0155_run-01_T1w*\",\n",
        "    r\"*sub-OAS30059_ses-d0230_run-01_T1w*\",\n",
        "    r\"*sub-OAS30459_ses-d0078_run-01_T1w*\"  # .nii.gz or any suffix\n",
        "]\n",
        "\n",
        "REMOVE_PATTERNS = oasis_filenames + nimhrv_filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "remove_images",
      "metadata": {
        "name": "remove_images"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Remove images with certain names or patterns\n",
        "# ------------------------------------------------------------\n",
        "import fnmatch\n",
        "\n",
        "# Determine which column to use for filtering\n",
        "col = 'image_path'\n",
        "print(\"DataFrame columns:\", df_all.columns)\n",
        "print(\"\\nSample filenames:\")\n",
        "if 'image_path' in df_all.columns:\n",
        "    print(df_all['image_path'].head())\n",
        "print(\"\\nDataFrame shape before removal:\", df_all.shape)\n",
        "\n",
        "if col:\n",
        "    mask = df_all[col].astype(str).apply(\n",
        "        lambda x: any(fnmatch.fnmatch(x, p) for p in REMOVE_PATTERNS)\n",
        "    )\n",
        "else:\n",
        "    mask = pd.Series(False, index=df_all.index)\n",
        "\n",
        "if mask.any():\n",
        "    print(f\"Removing {mask.sum()} rows matching patterns: {REMOVE_PATTERNS}\")\n",
        "    df_all = df_all.loc[~mask].copy()\n",
        "else:\n",
        "    print('No rows removed; no filename or image_name patterns matched.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce2e069c",
      "metadata": {},
      "source": [
        "### Train / Val / Test Split Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4a09b26",
      "metadata": {
        "name": "split"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Build explicit TRAIN / VAL / TEST partitions\n",
        "# ------------------------------------------------------------\n",
        "train_lower = [d.lower() for d in TRAIN_DATASETS]\n",
        "test_lower  = [d.lower() for d in TEST_DATASETS]\n",
        "\n",
        "if set(train_lower) & set(test_lower):\n",
        "    raise ValueError('A dataset appears in both TRAIN_DATASETS and TEST_DATASETS')\n",
        "\n",
        "all_datasets_lower = df_all['dataset'].str.lower()\n",
        "is_train = all_datasets_lower.isin(train_lower)\n",
        "is_test  = all_datasets_lower.isin(test_lower)\n",
        "\n",
        "if DROP_OTHER_DATASETS:\n",
        "    used_mask = is_train | is_test\n",
        "    dropped   = df_all.loc[~used_mask, 'dataset'].unique()\n",
        "    if len(dropped):\n",
        "        print(' ⚠️  Dropping datasets (not in either list):', dropped)\n",
        "    df_all   = df_all[used_mask].copy()\n",
        "    is_train = is_train.loc[df_all.index]\n",
        "    is_test  = is_test .loc[df_all.index]\n",
        "\n",
        "# ---------- split ----------------------------------------------------------\n",
        "df_train_full = df_all[is_train].copy()\n",
        "df_test       = df_all[is_test ].copy()\n",
        "\n",
        "if VAL_FRACTION > 0 and not df_train_full.empty:\n",
        "    df_train, df_val = train_test_split(\n",
        "        df_train_full,\n",
        "        test_size   = VAL_FRACTION,\n",
        "        random_state= RANDOM_STATE,\n",
        "        stratify    = df_train_full[['modality','sex']]\n",
        "    )\n",
        "else:\n",
        "    df_train = df_train_full.copy()\n",
        "    df_val   = pd.DataFrame(columns=df_all.columns)\n",
        "\n",
        "# Check for overlapping subjects between train and validation sets\n",
        "if not df_val.empty:\n",
        "    train_subjects = set(df_train['subject_id'])\n",
        "    val_subjects = set(df_val['subject_id'])\n",
        "    overlap = train_subjects & val_subjects\n",
        "\n",
        "    print(f\"Number of unique subjects in training set: {len(train_subjects)}\")\n",
        "    print(f\"Number of unique subjects in validation set: {len(val_subjects)}\")\n",
        "    print(f\"Number of overlapping subjects: {len(overlap)}\")\n",
        "\n",
        "    if overlap:\n",
        "        print(\"\\nOverlapping subjects:\")\n",
        "        for subject in sorted(overlap):\n",
        "            print(f\"- {subject}\")\n",
        "else:\n",
        "    print(\"Validation set is empty - no overlap check needed\")\n",
        "\n",
        "print(f'Total rows used : {len(df_all):,}')\n",
        "print(f'  TRAIN : {len(df_train):,}')\n",
        "print(f'  VAL   : {len(df_val):,}')\n",
        "print(f'  TEST  : {len(df_test):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "compute_weights",
      "metadata": {
        "name": "compute_weights"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Compute sample weights for TRAIN / VAL / TEST\n",
        "# ------------------------------------------------------------\n",
        "def add_sample_weights(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Add inverse-frequency sample weights per (age_bin, modality, sex).\"\"\"\n",
        "    df = df.copy()\n",
        "    # 1-year age bins\n",
        "    df['age_bin'] = df['age'].astype(int)\n",
        "    # count occurrences\n",
        "    freq = df.groupby(['age_bin','modality','sex']).size().rename('freq')\n",
        "    df = df.join(freq, on=['age_bin','modality','sex'])\n",
        "    # inverse frequency\n",
        "    df['sample_weight'] = 1.0 / df['freq']\n",
        "    # normalize weights\n",
        "    df['sample_weight'] /= df['sample_weight'].sum()\n",
        "    # drop helper columns\n",
        "    return df.drop(columns=['age_bin','freq'])\n",
        "\n",
        "# apply to each split\n",
        "df_train = add_sample_weights(df_train)\n",
        "df_val   = add_sample_weights(df_val)   if not df_val.empty else df_val\n",
        "df_test  = add_sample_weights(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "minimal_subset",
      "metadata": {
        "name": "minimal_subset"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Build MINIMAL tuning subsets (male, t1, age 30-40 by default)\n",
        "# ------------------------------------------------------------\n",
        "df_train_min = df_train.query(\n",
        "    'sex == @SUBSET_SEX and modality == @SUBSET_MODALITY and @SUBSET_AGE_MIN <= age <= @SUBSET_AGE_MAX'\n",
        ").copy()\n",
        "df_val_min = (df_val.query(\n",
        "    'sex == @SUBSET_SEX and modality == @SUBSET_MODALITY and @SUBSET_AGE_MIN <= age <= @SUBSET_AGE_MAX'\n",
        ").copy() if not df_val.empty else df_val.copy())\n",
        "df_test_min = df_test.query(\n",
        "    'sex == @SUBSET_SEX and modality == @SUBSET_MODALITY and @SUBSET_AGE_MIN <= age <= @SUBSET_AGE_MAX'\n",
        ").copy()\n",
        "\n",
        "# Re-compute weights inside the minimal subsets\n",
        "df_train_min = add_sample_weights(df_train_min) if not df_train_min.empty else df_train_min\n",
        "df_val_min   = add_sample_weights(df_val_min)   if not df_val_min.empty else df_val_min\n",
        "df_test_min  = add_sample_weights(df_test_min)  if not df_test_min.empty else df_test_min\n",
        "\n",
        "print(f\"Minimal subset sizes – TRAIN: {len(df_train_min)}, VAL: {len(df_val_min)}, TEST: {len(df_test_min)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd52de6",
      "metadata": {
        "name": "persist_split"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# Save split to CSV files (full & minimal subsets)\n",
        "# ------------------------------------------------------------\n",
        "df_train.to_csv(LABEL_DIR / 'train.csv', index=False)\n",
        "df_val.to_csv(LABEL_DIR / 'val.csv',   index=False)\n",
        "df_test.to_csv(LABEL_DIR / 'test.csv', index=False)\n",
        "\n",
        "# --- minimal subset CSVs ---------------------------------------------------\n",
        "df_train_min.to_csv(LABEL_DIR / 'train_min.csv', index=False)\n",
        "df_val_min.to_csv(LABEL_DIR / 'val_min.csv',     index=False)\n",
        "df_test_min.to_csv(LABEL_DIR / 'test_min.csv',   index=False)\n",
        "\n",
        "print(f'Saved files to {LABEL_DIR.resolve()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc8a52ca",
      "metadata": {},
      "source": [
        "### Train Set Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "053e1684",
      "metadata": {
        "name": "train_analysis"
      },
      "outputs": [],
      "source": [
        "quick_plots(df_train, 'TRAIN set')\n",
        "train_subset = coverage_report(df_train, 'TRAIN coverage')\n",
        "train_subset.to_csv(LABEL_DIR / 'train_one_per_combo.csv', index=False)\n",
        "plot_count_heatmap(df_train, 'TRAIN set')\n",
        "print(f'Saved train_one_per_combo.csv to {LABEL_DIR.resolve()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7d2817",
      "metadata": {},
      "source": [
        "### Validation Set Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0daaea",
      "metadata": {
        "name": "val_analysis"
      },
      "outputs": [],
      "source": [
        "if not df_val.empty:\n",
        "    quick_plots(df_val, 'VAL set')\n",
        "    val_subset = coverage_report(df_val, 'VAL coverage')\n",
        "    val_subset.to_csv(LABEL_DIR / 'val_one_per_combo.csv', index=False)\n",
        "    plot_count_heatmap(df_val, 'VAL set')\n",
        "    print(f'Saved val_one_per_combo.csv to {LABEL_DIR.resolve()}')\n",
        "else:\n",
        "    print('VAL set is empty – no analysis performed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96bc697",
      "metadata": {},
      "source": [
        "### Test Set Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f175f0",
      "metadata": {
        "name": "test_analysis"
      },
      "outputs": [],
      "source": [
        "quick_plots(df_test, 'TEST set')\n",
        "test_subset = coverage_report(df_test, 'TEST coverage')\n",
        "test_subset.to_csv(LABEL_DIR / 'test_one_per_combo.csv', index=False)\n",
        "plot_count_heatmap(df_test, 'TEST set')\n",
        "print(f'Saved test_one_per_combo.csv to {LABEL_DIR.resolve()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf95409",
      "metadata": {},
      "source": [
        "### Full (Train + Val + Test) Dataset Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d05febc4",
      "metadata": {
        "name": "full_analysis"
      },
      "outputs": [],
      "source": [
        "quick_plots(df_all, 'FULL dataset (used rows only)')\n",
        "_ = coverage_report(df_all, 'FULL coverage')\n",
        "plot_count_heatmap(df_all, 'FULL dataset')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
